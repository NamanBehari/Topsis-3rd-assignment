# -*- coding: utf-8 -*-
"""Untitled3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Hqza16_Lsfnrrgh487_p6Cu5IF9VZd8t
"""

# Install required libraries
!pip install pandas numpy matplotlib seaborn

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Define models and their performance metrics
models = ["GPT-4", "LLaMA-2", "Falcon-40B", "BART", "T5", "Bloom"]
criteria = ["Perplexity (‚Üì)", "BLEU Score (‚Üë)", "ROUGE Score (‚Üë)", "Inference Speed (‚Üë)", "Model Size (‚Üì)", "Training Time (‚Üì)"]

# Decision Matrix (Lower Perplexity is better, Higher BLEU, ROUGE, Speed are better)
decision_matrix = np.array([
    [15.2, 0.86, 0.78, 120, 1800, 100],  # GPT-4
    [18.4, 0.82, 0.75, 140, 1600, 90],   # LLaMA-2
    [16.8, 0.85, 0.76, 130, 1700, 95],   # Falcon-40B
    [20.5, 0.80, 0.74, 110, 1500, 85],   # BART
    [21.2, 0.78, 0.72, 105, 1400, 80],   # T5
    [23.0, 0.75, 0.70, 100, 1350, 75]    # Bloom
])

# Define weights for each criterion (Higher weight = More important)
weights = np.array([0.25, 0.2, 0.2, 0.15, 0.1, 0.1])

# Benefit (‚Üë) or Cost (‚Üì) criteria (1 for benefit, -1 for cost)
benefit_cost = np.array([-1, 1, 1, 1, -1, -1])  # Perplexity, Model Size, and Training Time are costs

# Step 1: Normalize the Decision Matrix
norm_matrix = decision_matrix / np.sqrt((decision_matrix ** 2).sum(axis=0))

# Step 2: Multiply by Weights
weighted_matrix = norm_matrix * weights

# Step 3: Identify Ideal and Negative-Ideal Solutions
ideal_solution = np.max(weighted_matrix, axis=0) * (benefit_cost == 1) + np.min(weighted_matrix, axis=0) * (benefit_cost == -1)
negative_ideal_solution = np.min(weighted_matrix, axis=0) * (benefit_cost == 1) + np.max(weighted_matrix, axis=0) * (benefit_cost == -1)

# Step 4: Compute Euclidean Distance from Ideal and Negative-Ideal Solutions
distance_to_ideal = np.sqrt(((weighted_matrix - ideal_solution) ** 2).sum(axis=1))
distance_to_negative = np.sqrt(((weighted_matrix - negative_ideal_solution) ** 2).sum(axis=1))

# Step 5: Compute TOPSIS Scores
topsis_score = distance_to_negative / (distance_to_ideal + distance_to_negative)

# Rank models based on TOPSIS Score
ranking = np.argsort(topsis_score)[::-1]

# Display the results in a DataFrame
results = pd.DataFrame({
    "Model": np.array(models)[ranking],
    "TOPSIS Score": topsis_score[ranking]
})

# Print the ranking in a nicely formatted table
print("\nüèÜ Ranking of Text Generation Models using TOPSIS:\n")
print(results.to_markdown(index=False))

# Create a bar chart to visualize the rankings
plt.figure(figsize=(10, 5))
sns.barplot(x=results["TOPSIS Score"], y=results["Model"], palette="viridis")
plt.xlabel("TOPSIS Score (Higher is Better)")
plt.ylabel("Text Generation Model")
plt.title("Best Pre-Trained Text Generation Models (TOPSIS Ranking)")
plt.grid(axis="x", linestyle="--", alpha=0.5)
plt.show()

# Explanation of results
print("\nüìå **Explanation of Results:**\n")
print("- The model with the **highest TOPSIS score** is considered the best overall choice.")
print("- **GPT-4** performs the best, as it balances all criteria effectively (perplexity, BLEU, ROUGE, speed, etc.).")
print("- Models like **Bloom and T5** rank lower due to higher perplexity and lower BLEU/ROUGE scores.")
print("- The ranking provides a data-driven approach to choosing the best text generation model.")